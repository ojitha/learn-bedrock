{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc56ff5",
   "metadata": {},
   "source": [
    "## Chatbot Agent\n",
    "Agent base chatbot using Amazon Bedrock and LangGraph.\n",
    "This bot has memeory capablilities to remember the previous prompts in the same conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "boto3.set_stream_logger('', logging.ERROR)\n",
    "\n",
    "# Initialize AWS Bedrock client\n",
    "bedrock_client = boto3.client(\n",
    "    service_name='bedrock-runtime'\n",
    "    ,region_name='ap-southeast-2'\n",
    ")\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"amazon.nova-pro-v1:0\",  \n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.3,  # Same temperature as original\n",
    "        \"maxTokenCount\": 1000\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c98958",
   "metadata": {},
   "source": [
    "load LangSmith environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b472981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd8579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b43e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "travily_search = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5541d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current date and time\n",
    "import datetime\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_current_date():\n",
    "    \"\"\"\n",
    "    Get the current date and time.\n",
    "    Use this tool first for any tile-based queries.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692777df",
   "metadata": {},
   "source": [
    "Bind the LLM to tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d9954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([get_current_date, travily_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68673511",
   "metadata": {},
   "source": [
    "Define the nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": llm_with_tools.invoke(state[\"messages\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fdf0e2",
   "metadata": {},
   "source": [
    "Define the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[get_current_date, travily_search])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26c404",
   "metadata": {},
   "source": [
    "## Add edges\n",
    "\n",
    "This is a conditional edge that will only be taken if the tool condition is met:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cb96a6",
   "metadata": {},
   "source": [
    "If tools are used, return to the chatbot to process the tool output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dbbaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(\"tools\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4fd772",
   "metadata": {},
   "source": [
    "Set the entry point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fea4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d301ba1c",
   "metadata": {},
   "source": [
    "Compile the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69630a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c27db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "def render_in_markdown(text):\n",
    "    display(Markdown(text))\n",
    "    \n",
    "def process_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "    return message   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b466c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query, config=None):\n",
    "    inputs = {\"messages\": [(\"user\", query)]}\n",
    "    message = process_stream(graph.stream(inputs, config, stream_mode=\"values\"))\n",
    "    render_in_markdown(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba245f",
   "metadata": {},
   "source": [
    "Is agent can remember me?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8caec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_query(\"My name is Ojitha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_query(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d05184",
   "metadata": {},
   "source": [
    "As shown in the above output, model cannot remember. Therefore, need to save to the memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36d482",
   "metadata": {},
   "source": [
    "Now recompile and pass the memory object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62209777",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b5130",
   "metadata": {},
   "source": [
    "Memory is dedicated to user session, therefore you need to pass the configuration as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458352ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_user_1 = {\"thread_id\": \"user_1\"}\n",
    "process_query(\"My name is Ojitha\", config=cfg_user_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9879ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_query(\"What is my name?\", config=cfg_user_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-bedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
